---
title: "ML_Final_Project"
output: html_document
---
Background: 

In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

I will need to build a model, cross validate it and predict 20 different test cases.

Loading data 
---
```{r}
library(caret)
#setwd("C:/Users/Alfonso/Desktop/JOM/Practical_Machine_Learning")
setwd("C:/Users/JosePortatil/Dropbox/Data Science/Practical_Machine_Learning")
training<-read.csv("pml-training.csv",header=T,na.strings = "")
testing<-read.csv("pml-testing.csv",header=T,na.strings = "")
```


cleaning data
---

Cleaning Trainin data: 

There are several columns that are not important for the analysis and should be dropped. 

```{r}
#Drop Not relevant Columns. 
training$X<-NULL
training$user_name<-NULL 
training$raw_timestamp_part_1<-NULL
training$raw_timestamp_part_2<-NULL
training$cvtd_timestamp<-NULL
training$new_window<-NULL
training$num_window<-NULL
training$problem_id<-NULL
```

Almost all columns represents numeric values but they are in factor type. 
We must convert them to numeric values. 
```{r,warning=FALSE}
#Convert COlumn Variables to Numeric [First convert to Character then to Numeric]
training[, -c(153)] <- sapply(training[,-c(153)], as.character)
training[, -c(153)] <- sapply(training[,-c(153)], as.numeric)
```

Looking a summary of the data it can be seen a lot of NA values in columns.These columns can be dropped because they do not bring value to the model. 

```{r}
#Drop columns with lots of NA values 
delete_columns<-which(colSums(is.na(training))>19000)
training<-training[,-c(delete_columns)]
```

Cleaning Testing Data: 

The same process is done in the Tetsing Data. 

```{r,warning=FALSE}
#Drop Not relevant Columns. 
testing$X<-NULL
testing$user_name<-NULL 
testing$raw_timestamp_part_1<-NULL
testing$raw_timestamp_part_2<-NULL
testing$cvtd_timestamp<-NULL
testing$new_window<-NULL
testing$num_window<-NULL
testing$problem_id<-NULL

#Convert COlumn Variables to Numeric [First convert to Character then to Numeric]
testing[, -c(153)] <- sapply(testing[,-c(153)], as.character)
testing[, -c(153)] <- sapply(testing[,-c(153)], as.numeric)

#Drop columns with lots of NA values 
testing<-testing[,-c(delete_columns)]
```

create a model and cross validate
---

The training set is a little big for my computer and the random forest model training would take too much time. To tackle this i will take a sample of 2000 observation from my training data  and another 2000 observation sample to validate model. 

```{r}
# take a random sample of size 2000 from a dataset mydata 
# sample without replacement
training_sample <- training[sample(1:nrow(training), 2000,
                          replace=FALSE),]
#A testing set 
test_sample<- training[sample(1:nrow(training), 2000,
                                   replace=FALSE),]
```


Now a random forest with cross validation will be  trained and tested in another data set. A confusion Matrix will be displayed.

```{r}
# define training control
train_control <- trainControl(method="cv", number=10)
# train the model 
model <- train(classe~., data=training_sample, trControl=train_control, method="rf")
# make predictions on testing set and make confusion Matrix
predictions <- predict(model, test_sample[,1:52])
# summarize results
confusionMatrix(predictions, test_sample$classe)
```

The results performed and accuracy is very high so we proceed to predict values on the test set provided. 

Predict 
---

```{r}
Final_predictions <- predict(model, testing)
Final_predictions
```



